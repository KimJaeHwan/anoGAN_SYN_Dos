{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from pylab import rcParams\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.sampler import RandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from torchensemble import VotingClassifier\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "RANDOM_SEED = 42\n",
    "LABELS = [\"Normal\", \"Fraud\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 정보 확인\n",
    "- 해당 데이터는 SYN_Dos공격을 시도하는 패킷이 포함된 패킷데이터들이다 \n",
    "- 정상데이터와 이상 데이터(공격)의 차이가 많이 나는 것을 알 수 있다. \n",
    "\n",
    "- 일반적인 지도학습이 아닌 비지도학습의 이상 탐지 모델을 구성한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2771276, 2) (2771275, 115)\n",
      "False\n",
      "0    2764238\n",
      "1       7038\n",
      "Name: x, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_label = pd.read_csv(\"./data/SYN_DoS_labels.csv\")\n",
    "df_data = pd.read_csv(\"./data/SYN_DoS_dataset.csv\")\n",
    "\n",
    "print(df_label.shape, df_data.shape)\n",
    "print(df_label.isnull().values.any())\n",
    "count_classes = pd.value_counts(df_label[\"x\"], sort=True)\n",
    "print(count_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "- 라벨과 데이터 합치기\n",
    "- 훈련세트, 테스트 세트 분리\n",
    "- 훈련데이터는 정상데이터만 존재하도록 이상데이터 제거\n",
    "- 훈련데이터의 라벨정보 제거\n",
    "\n",
    "- 테스트 데이터의 라벨과 데이터 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "df_data = pd.DataFrame(StandardScaler().fit_transform(df_data))\n",
    "df_data_set = pd.concat([df_data, df_label], axis=1)\n",
    "X_train, X_test = train_test_split(df_data_set, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_train = X_train[X_train.x == 0]\n",
    "X_train = X_train.drop(['Unnamed: 0', 'x'], axis=1)\n",
    "\n",
    "Y_test = X_test['x']\n",
    "X_test = X_test.drop(['Unnamed: 0','x'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(X_train.values, batch_size=batch_size , drop_last=True)\n",
    "test_loader = DataLoader(X_test.values, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성\n",
    "- noise데이터를 입력 데이터와 같은 (,115) 사이즈로 만드는 Generator모델 구현\n",
    "- 구현된 이미지를 판별하는 Discriminator 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator 모델\n",
    "- 모델 layer는다음과 같다\n",
    "\n",
    "(16,1) -> (16,5) -> (8, 12) -> (4, 27) -> (2, 56) -> (1, 115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            self.create_trans_block(16,16,5,1),\n",
    "            self.create_trans_block(16,8,4,2),\n",
    "            self.create_trans_block(8,4,5,2),\n",
    "            self.create_trans_block(4,2,4,2),\n",
    "            self.create_trans_block(2,1,5,2,True)\n",
    "        )\n",
    "    def create_trans_block(self, in_channels, out_channels, kernel_size, stride, final_layer=False):\n",
    "        if final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose1d(in_channels,out_channels, kernel_size, stride),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels,out_channels, kernel_size, stride),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        output = self.gen(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator 모델\n",
    "- 모델 layer는 Generator모델과 비슷하다\n",
    "\n",
    "(1, 115) -> (2,56) -> (4, 27) -> (8, 12) -> (16,5) -> (16,1) -> (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.disc = nn.Sequential(\n",
    "            self.create_conv_block(1,2,5,2),\n",
    "            self.create_conv_block(2,4,4,2),\n",
    "            self.create_conv_block(4,8,5,2),\n",
    "            self.create_conv_block(8,16,4,2),\n",
    "            self.create_conv_block(16,16,5,1),\n",
    "            self.create_conv_block(16,1,1,1, True)\n",
    "        )\n",
    "        \n",
    "    def create_conv_block(self, in_channels, out_channels, kernel_size, stride, final_layer=False):\n",
    "        if final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size, stride),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, stride),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        disc_pred = self.disc(x)\n",
    "        return disc_pred.view(len(disc_pred), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator().to(device)\n",
    "disc = Discriminator().to(device)\n",
    "\n",
    "gen_optimizer = optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "disc_optimizer = optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "gen = gen.apply(weights_init)\n",
    "disc = disc.apply(weights_init)\n",
    "\n",
    "loss_func = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델학습\n",
    "## Generator , Discriminator 학습\n",
    "- AnoGAN을 사용하기 위해서는 정상데이터를 생성할 수 있는 gen과 판별할 수 있는 Disc가 필요하다. 따라서 먼저 Generator와 Discriminator모델을 학습 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690925b4d76c4e72b9bf85a9ffee9e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 0.00033908603191375733, discriminator loss: 7.788984477519988e-06\n",
      "Step 10000: Generator loss: 3.8252667669296265, discriminator loss: 0.0541493919480592\n",
      "Step 20000: Generator loss: 4.307848157048225, discriminator loss: 0.020362119425088167\n",
      "Step 30000: Generator loss: 4.470466265439987, discriminator loss: 0.02823822200144641\n",
      "Step 40000: Generator loss: 3.6195396302223206, discriminator loss: 0.10860043844496832\n",
      "Step 50000: Generator loss: 4.442154331707955, discriminator loss: 0.03703383241319098\n",
      "Step 60000: Generator loss: 4.750598274779319, discriminator loss: 0.02651178147145547\n",
      "epoch: 2/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174c5b84f7534dafa1c46c4dc0f9f2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 3.9377002461433412, discriminator loss: 0.045421467205742375\n",
      "Step 10000: Generator loss: 4.827894777655602, discriminator loss: 0.02362388251693919\n",
      "Step 20000: Generator loss: 4.9875442137002945, discriminator loss: 0.020555819198628887\n",
      "Step 30000: Generator loss: 5.305496211504936, discriminator loss: 0.013530970534810331\n",
      "Step 40000: Generator loss: 5.36303791782856, discriminator loss: 0.029226062547380572\n",
      "Step 50000: Generator loss: 5.051226199698448, discriminator loss: 0.02369337048290763\n",
      "Step 60000: Generator loss: 5.458726091742515, discriminator loss: 0.01821863055282738\n",
      "epoch: 3/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb2bd92ba8f400daeafb28e89d8dba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 5.185699772834778, discriminator loss: 0.0060851250603795055\n",
      "Step 10000: Generator loss: 5.8454117185354235, discriminator loss: 0.009322188862797339\n",
      "Step 20000: Generator loss: 5.866259320259094, discriminator loss: 0.015509363841766027\n",
      "Step 30000: Generator loss: 5.961174696874618, discriminator loss: 0.013418280553328804\n",
      "Step 40000: Generator loss: 6.127811394691467, discriminator loss: 0.005115952732181177\n",
      "Step 50000: Generator loss: 5.84218287513256, discriminator loss: 0.016304846039961556\n",
      "Step 60000: Generator loss: 6.2438129251956935, discriminator loss: 0.012483395223820117\n",
      "epoch: 4/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79470c43f92d4be8a7e0fb04b0b249ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 5.799299423837661, discriminator loss: 0.0070155923549435105\n",
      "Step 10000: Generator loss: 6.454559118461609, discriminator loss: 0.009686691365056323\n",
      "Step 20000: Generator loss: 6.814426398468018, discriminator loss: 0.010742893935149187\n",
      "Step 30000: Generator loss: 6.699080763959885, discriminator loss: 0.0032867771499732043\n",
      "Step 40000: Generator loss: 6.789499607181549, discriminator loss: 0.0037284038588841213\n",
      "Step 50000: Generator loss: 6.972005105781555, discriminator loss: 0.01020773453861766\n",
      "Step 60000: Generator loss: 7.1938998016834255, discriminator loss: 0.009368891771606287\n",
      "epoch: 5/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a226e27c20486492effd09d452c4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 6.2253628182888034, discriminator loss: 0.0038510409109672765\n",
      "Step 10000: Generator loss: 6.808587849807739, discriminator loss: 0.0037124951726262225\n",
      "Step 20000: Generator loss: 7.133867909193039, discriminator loss: 0.0020269263334193963\n",
      "Step 30000: Generator loss: 7.131319821214676, discriminator loss: 0.0034346362818323544\n",
      "Step 40000: Generator loss: 6.593742679095269, discriminator loss: 0.017816271215380403\n",
      "Step 50000: Generator loss: 7.254196745920181, discriminator loss: 0.015359824738759199\n",
      "Step 60000: Generator loss: 6.724157750415802, discriminator loss: 0.006829480647452874\n",
      "epoch: 6/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c05dba0ecdd4b4ba8cc42e96b4cce7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 6.122065392065048, discriminator loss: 0.004154185394811793\n",
      "Step 10000: Generator loss: 7.078497610712051, discriminator loss: 0.004707819593563908\n",
      "Step 20000: Generator loss: 7.312022033214569, discriminator loss: 0.007454101328925753\n",
      "Step 30000: Generator loss: 6.99857629275322, discriminator loss: 0.0033401334531401516\n",
      "Step 40000: Generator loss: 7.117808535671234, discriminator loss: 0.004052040207289974\n",
      "Step 50000: Generator loss: 7.643967618083954, discriminator loss: 0.007706045125087257\n",
      "Step 60000: Generator loss: 7.679621279430389, discriminator loss: 0.013948885128642723\n",
      "epoch: 7/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccfc5490868d464c96819a89df7b8dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 6.980477897024155, discriminator loss: 0.005513824981651851\n",
      "Step 10000: Generator loss: 7.149642756223678, discriminator loss: 0.00644917522877222\n",
      "Step 20000: Generator loss: 7.118114509630203, discriminator loss: 0.002323991714103613\n",
      "Step 30000: Generator loss: 7.379327279996872, discriminator loss: 0.0038985782306874173\n",
      "Step 40000: Generator loss: 7.224942586565017, discriminator loss: 0.012742074859664717\n",
      "Step 50000: Generator loss: 6.897809051942826, discriminator loss: 0.019389387401736166\n",
      "Step 60000: Generator loss: 6.927951517724991, discriminator loss: 0.0134354304243956\n",
      "epoch: 8/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3745489fce04af8a728fd99d32a9431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 5.908337454628945, discriminator loss: 0.00547050154680328\n",
      "Step 10000: Generator loss: 7.27496956102848, discriminator loss: 0.01587301196465851\n",
      "Step 20000: Generator loss: 7.22212848520279, discriminator loss: 0.011163341732199478\n",
      "Step 30000: Generator loss: 7.671071243286133, discriminator loss: 0.011039558113197564\n",
      "Step 40000: Generator loss: 7.313666865539551, discriminator loss: 0.005865526858976227\n",
      "Step 50000: Generator loss: 7.4543651125431065, discriminator loss: 0.003676399757435138\n",
      "Step 60000: Generator loss: 7.700431641769409, discriminator loss: 0.004967223440132511\n",
      "epoch: 9/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea678034650440f9969568342f874b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 6.936506122112275, discriminator loss: 0.008547917389514624\n",
      "Step 10000: Generator loss: 7.25003436961174, discriminator loss: 0.004365949316573097\n",
      "Step 20000: Generator loss: 8.130868333292007, discriminator loss: 0.007660867297516961\n",
      "Step 30000: Generator loss: 7.777557878065109, discriminator loss: 0.010469959077493695\n",
      "Step 40000: Generator loss: 6.921898964214325, discriminator loss: 0.007174876800559287\n",
      "Step 50000: Generator loss: 7.072210332107544, discriminator loss: 0.005876298557955306\n",
      "Step 60000: Generator loss: 7.159366323971748, discriminator loss: 0.02878770882698882\n",
      "epoch: 10/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93eed9b30ddb45ef80faad6544986647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 5.994088495349884, discriminator loss: 0.005701589096919634\n",
      "Step 10000: Generator loss: 6.720675898122788, discriminator loss: 0.01490283560326061\n",
      "Step 20000: Generator loss: 6.650910083913803, discriminator loss: 0.018121148462715793\n",
      "Step 30000: Generator loss: 7.25326852915287, discriminator loss: 0.019083777003435533\n",
      "Step 40000: Generator loss: 7.9785629683256145, discriminator loss: 0.02108479037231591\n",
      "Step 50000: Generator loss: 7.302574071645736, discriminator loss: 0.006288091585634538\n",
      "Step 60000: Generator loss: 7.250680687999726, discriminator loss: 0.0043601066696835914\n",
      "epoch: 11/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa728a10a1744ea8959984b06c34218a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 7.069823157835007, discriminator loss: 0.014675809249024315\n",
      "Step 10000: Generator loss: 7.754125662326813, discriminator loss: 0.007007111733595957\n",
      "Step 20000: Generator loss: 7.401147931957245, discriminator loss: 0.0033790570802491857\n",
      "Step 30000: Generator loss: 7.704606841850281, discriminator loss: 0.0015044137298580607\n",
      "Step 40000: Generator loss: 7.868585386371612, discriminator loss: 0.00620522765355854\n",
      "Step 50000: Generator loss: 7.506164023637772, discriminator loss: 0.004293500769708771\n",
      "Step 60000: Generator loss: 8.061026996088028, discriminator loss: 0.004912619987176731\n",
      "epoch: 12/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45d738c638541e4bbc291c59449557d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 6.85511525888443, discriminator loss: 0.0032994682445350917\n",
      "Step 10000: Generator loss: 8.345499678945542, discriminator loss: 0.012502860634223907\n",
      "Step 20000: Generator loss: 7.570426333618164, discriminator loss: 0.01286045821612497\n",
      "Step 30000: Generator loss: 7.441562355756759, discriminator loss: 0.0022945198871202593\n",
      "Step 40000: Generator loss: 7.905408009147644, discriminator loss: 0.00727895856625546\n",
      "Step 50000: Generator loss: 8.616937766361236, discriminator loss: 0.013116033937356405\n",
      "Step 60000: Generator loss: 8.722523396492004, discriminator loss: 0.00840967992020378\n",
      "epoch: 13/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a62d35405ab42c8b72c83b0c3276080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 7.909642031574249, discriminator loss: 0.006997873302989319\n",
      "Step 10000: Generator loss: 8.683683596515655, discriminator loss: 0.006338884943972516\n",
      "Step 20000: Generator loss: 8.200109964418411, discriminator loss: 0.004455513737332512\n",
      "Step 30000: Generator loss: 8.37110782494545, discriminator loss: 0.005538099757001327\n",
      "Step 40000: Generator loss: 8.017238859653473, discriminator loss: 0.003955996006461646\n",
      "Step 50000: Generator loss: 8.238133829545975, discriminator loss: 0.007927128506769077\n",
      "Step 60000: Generator loss: 8.30689623298645, discriminator loss: 0.003421834251929249\n",
      "epoch: 14/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f57c9e275e42d9b888b394c27f2250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 7.821645119524002, discriminator loss: 0.006708304572975612\n",
      "Step 10000: Generator loss: 8.245791540002823, discriminator loss: 0.002331154636546853\n",
      "Step 20000: Generator loss: 7.461841971611976, discriminator loss: 0.011996708665174811\n",
      "Step 30000: Generator loss: 8.533535215330124, discriminator loss: 0.035964026711743646\n",
      "Step 40000: Generator loss: 9.200761283445358, discriminator loss: 0.00804473144273652\n",
      "Step 50000: Generator loss: 8.301220867538452, discriminator loss: 0.004318683155240433\n",
      "Step 60000: Generator loss: 8.146767605924607, discriminator loss: 0.003160295317045529\n",
      "epoch: 15/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79efe1ec3620463998926d3d2ee5075e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 7.796777449941636, discriminator loss: 0.0022976483138998447\n",
      "Step 10000: Generator loss: 8.95767376089096, discriminator loss: 0.003942016439682629\n",
      "Step 20000: Generator loss: 9.098364762210846, discriminator loss: 0.004373936662630149\n",
      "Step 30000: Generator loss: 9.223709937000274, discriminator loss: 0.005697154286613295\n",
      "Step 40000: Generator loss: 10.66085022764206, discriminator loss: 0.01463901186488656\n",
      "Step 50000: Generator loss: 8.354144186878205, discriminator loss: 0.013577543972280183\n",
      "Step 60000: Generator loss: 7.9310879584312435, discriminator loss: 0.02256632195341808\n",
      "epoch: 16/50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e84de9cfd6b411cb7bc5964d5c7c7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Generator loss: 6.8368821381568905, discriminator loss: 0.015274770275288028\n",
      "Step 10000: Generator loss: 8.096911487531662, discriminator loss: 0.004923761834559263\n",
      "Step 20000: Generator loss: 8.388513634967804, discriminator loss: 0.0019504381823653603\n",
      "Step 30000: Generator loss: 8.36556678814888, discriminator loss: 0.002107103249637294\n",
      "Step 40000: Generator loss: 9.313244748163223, discriminator loss: 0.002422224137455123\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_2656/6224229.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mgen_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mgen_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py38\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "display_step = 10000\n",
    "mean_gen_loss = 0\n",
    "mean_disc_loss = 0\n",
    "# 1 에포크당 15분 disc에 과적합 될가능성이 있음\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    print(f'epoch: {epoch}/{num_epochs}')\n",
    "    for j, packet in tqdm(enumerate(train_loader)):\n",
    "        packet = packet.to(device).float()\n",
    "\n",
    "        disc_optimizer.zero_grad()\n",
    "        noise = torch.randn(batch_size, 16, 1 ,device=device)\n",
    "        gen_packet = gen(noise)\n",
    "        disc_fake = disc(gen_packet.detach())\n",
    "        disc_real = disc(packet.view(batch_size, 1, 115))\n",
    "        #disc_real = disc(packet.view(-1, 1, 115))    # 테스트 필요\n",
    "        disc_loss_fake = loss_func(disc_fake, torch.zeros_like(disc_fake))\n",
    "        disc_loss_real = loss_func(disc_real, torch.ones_like(disc_real))\n",
    "\n",
    "        disc_loss = (disc_loss_fake + disc_loss_real) / 2\n",
    "\n",
    "        mean_disc_loss += disc_loss.item()\n",
    "\n",
    "        disc_loss.backward(retain_graph = True)\n",
    "        disc_optimizer.step()\n",
    "\n",
    "        gen_optimizer.zero_grad()\n",
    "\n",
    "        noise = torch.randn(batch_size, 16, 1, device=device)\n",
    "        gen_packet = gen(noise)\n",
    "        disc_fake = disc(gen_packet)\n",
    "\n",
    "        gen_loss = loss_func(disc_fake, torch.ones_like(disc_fake))\n",
    "        mean_gen_loss += gen_loss.item() \n",
    "\n",
    "        gen_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "\n",
    "        if( j == 0 or j % display_step == 0 ):\n",
    "            print(f\"Step {j}: Generator loss: {mean_gen_loss / display_step}, discriminator loss: {mean_disc_loss / display_step}\")\n",
    "            mean_disc_loss = 0\n",
    "            mean_gen_loss = 0\n",
    "    # 장기 학습시 사용\n",
    "    torch.save(gen, \"./model/anoGAN_SYN_Dos_gen.pt\")\n",
    "    torch.save(disc, \"./model/anoGAN_SYN_Dos_disc.pt\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "267afb14fdf7b26847449cf4f7f0cd28ba2362ced1c6cba84d03c7f1c52756fc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
